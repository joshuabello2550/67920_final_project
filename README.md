# RLPrompt with GRPO and Soft Q-Learning

This repository contains the code and experiments for the project RLPrompt with GRPO and Log-Likelihood Rewards by Joshua Bello (MIT).
The work extends RLPrompt (Deng et al., 2022) by comparing two reinforcement-learningâ€“based prompt optimization algorithmsâ€”Soft Q-Learning and Group Relative Policy Optimization (GRPO)â€”under multiple reward types and evaluating their performance on BoolQ and GSM8K.

[ðŸ“„ Read the full paper](./Paper.pdf)
